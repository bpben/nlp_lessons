{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Tokenization and Word counts for sentiment analysis\n",
    "In this assignment, you will be applying the techniques learned in week 1 of the course to perform and analyze sentiment on a dataset of movie reviews from IMDB.\n",
    "\n",
    "This dataset comes from [Mass et. al. (2011)](https://www.aclweb.org/anthology/P11-1015.pdf) and the full version is available [here](http://ai.stanford.edu/~amaas/data/sentiment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from collections import Counter\n",
    "import re\n",
    "from numpy import log, mean\n",
    "\n",
    "required = {'spacy', 'scikit-learn', 'pandas', 'transformers==2.4.1'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "I've saved a subset of the data in the data directory on the repository.  It is available as a pickled dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "pct_sample = 0.1\n",
    "all_text = {}\n",
    "for p in ['neg', 'pos']:\n",
    "    all_text[p] = []\n",
    "    for f in glob('/Users/batorsky/Downloads/aclImdb/test/%s/*.txt' % p):\n",
    "        if np.random.rand()<=pct_sample:\n",
    "            all_text[p].append(open(f, encoding='utf-8').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/assignment_1_reviews.pkl', 'wb') as f:\n",
    "    pickle.dump(all_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neg', 1233), ('pos', 1266)]\n"
     ]
    }
   ],
   "source": [
    "# you will need to change this to where ever the file is stored\n",
    "data_location = '../data/assignment_1_reviews.pkl'\n",
    "with open(data_location, 'rb') as f:\n",
    "    all_text = pickle.load(f)\n",
    "# corpora size\n",
    "print([(k, len(all_text[k])) for k in all_text])\n",
    "# for simplicity, let's split these into separate sets\n",
    "neg, pos = all_text.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Use what you've developed in the week 1 notebook to tokenize each of the corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "en = English()\n",
    "\n",
    "def simple_tokenizer(doc, model=en):\n",
    "    # a simple tokenizer for individual documents (different from above)\n",
    "    tokenized_docs = []\n",
    "    parsed = model(doc)\n",
    "    return([t.lower_ for t in parsed if (t.is_alpha)&(not t.like_url)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_neg = [simple_tokenizer(x) for x in neg]\n",
    "token_pos = [simple_tokenizer(x) for x in pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word counts\n",
    "Create a count of the number of words in each review.  Use scikit-learn's CountVectorizer.  Refer to the documentation as it has a few parameters you might want to think about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=simple_tokenizer)\n",
    "# should probably fit on the combined\n",
    "cv.fit(neg+pos)\n",
    "count_neg = cv.transform(neg).toarray()\n",
    "count_pos = cv.transform(pos).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use pandas DF here\n",
    "neg_df = pd.DataFrame(count_neg, columns=cv.get_feature_names())\n",
    "neg_df['positive'] = False\n",
    "pos_df = pd.DataFrame(count_pos, columns=cv.get_feature_names())\n",
    "pos_df['positive'] = True\n",
    "# combine for more ease\n",
    "all_df = pos_df.append(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaahhhhhhggg</th>\n",
       "      <th>aaaggghhhhhhh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aaam</th>\n",
       "      <th>aaja</th>\n",
       "      <th>aalcc</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaran</th>\n",
       "      <th>...</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zweite</th>\n",
       "      <th>à</th>\n",
       "      <th>é</th>\n",
       "      <th>étienne</th>\n",
       "      <th>être</th>\n",
       "      <th>ïts</th>\n",
       "      <th>über</th>\n",
       "      <th>ý</th>\n",
       "      <th>ýs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27053 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a  aa  aaaaaaahhhhhhggg  aaaggghhhhhhh  aaah  aaam  aaja  aalcc  aaliyah  \\\n",
       "0   3   0                 0              0     0     0     0      0        0   \n",
       "1   2   0                 0              0     0     0     0      0        0   \n",
       "2   2   0                 0              0     0     0     0      0        0   \n",
       "3  10   0                 0              0     0     0     0      0        0   \n",
       "4   6   0                 0              0     0     0     0      0        0   \n",
       "\n",
       "   aaran  ...  zwart  zweite  à  é  étienne  être  ïts  über  ý  ýs  \n",
       "0      0  ...      0       0  0  0        0     0    0     0  0   0  \n",
       "1      0  ...      0       0  0  0        0     0    0     0  0   0  \n",
       "2      0  ...      0       0  0  0        0     0    0     0  0   0  \n",
       "3      0  ...      0       0  0  0        0     0    0     0  0   0  \n",
       "4      0  ...      0       0  0  0        0     0    0     0  0   0  \n",
       "\n",
       "[5 rows x 27053 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words\n",
    "What are the top 10 most frequent words in the positive reviews? The negative reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(data, n=10):\n",
    "    return(\n",
    "        data.groupby('positive').sum().T.apply(lambda c: c.nlargest(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>positive</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>7548.0</td>\n",
       "      <td>8133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>6978.0</td>\n",
       "      <td>8905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>4248.0</td>\n",
       "      <td>3943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>4203.0</td>\n",
       "      <td>5093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>4952.0</td>\n",
       "      <td>5793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>4354.0</td>\n",
       "      <td>4553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>6402.0</td>\n",
       "      <td>7942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>15365.0</td>\n",
       "      <td>17182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>3837.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>6780.0</td>\n",
       "      <td>6658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "positive    False    True \n",
       "a          7548.0   8133.0\n",
       "and        6978.0   8905.0\n",
       "i          4248.0   3943.0\n",
       "in         4203.0   5093.0\n",
       "is         4952.0   5793.0\n",
       "it         4354.0   4553.0\n",
       "of         6402.0   7942.0\n",
       "that          NaN   3521.0\n",
       "the       15365.0  17182.0\n",
       "this       3837.0      NaN\n",
       "to         6780.0   6658.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there's a lot of pretty irrelevant words in the top here.  It's hard to really say anything about this.  Can you think of a way to get to more informative terms (i.e. ones that might give you some insight as to what words are positive versus negative?)\n",
    "\n",
    "Hint: Think about which tokens might be less informative.  Is there a way we learned to remove those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_stop = all_df.iloc[:, ~all_df.columns.isin(ENGLISH_STOP_WORDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['acting', 369.0, 236.0],\n",
       "       ['action', 154.0, 155.0],\n",
       "       ['actors', 265.0, 220.0],\n",
       "       ['actually', 253.0, 163.0],\n",
       "       ['awful', 147.0, nan],\n",
       "       ['bad', 668.0, 194.0],\n",
       "       ['beautiful', nan, 157.0],\n",
       "       ['best', 187.0, 440.0],\n",
       "       ['better', 298.0, 221.0],\n",
       "       ['big', 162.0, 179.0],\n",
       "       ['bit', nan, 171.0],\n",
       "       ['book', 142.0, nan],\n",
       "       ['boring', 149.0, nan],\n",
       "       ['br', 412.0, 404.0],\n",
       "       ['ca', 192.0, 168.0],\n",
       "       ['cast', 172.0, 220.0],\n",
       "       ['character', 364.0, 374.0],\n",
       "       ['characters', 365.0, 370.0],\n",
       "       ['come', 149.0, nan],\n",
       "       ['comedy', 155.0, 161.0],\n",
       "       ['course', nan, 154.0],\n",
       "       ['did', 637.0, 423.0],\n",
       "       ['director', 212.0, 240.0],\n",
       "       ['does', 521.0, 508.0],\n",
       "       ['dvd', nan, 185.0],\n",
       "       ['end', 265.0, 251.0],\n",
       "       ['especially', nan, 166.0],\n",
       "       ['excellent', nan, 183.0],\n",
       "       ['fact', 179.0, 165.0],\n",
       "       ['family', nan, 192.0],\n",
       "       ['far', 165.0, 149.0],\n",
       "       ['feel', nan, 175.0],\n",
       "       ['film', 1797.0, 2122.0],\n",
       "       ['films', 311.0, 377.0],\n",
       "       ['fun', nan, 154.0],\n",
       "       ['funny', 222.0, 205.0],\n",
       "       ['gets', 163.0, nan],\n",
       "       ['going', 229.0, 180.0],\n",
       "       ['good', 632.0, 811.0],\n",
       "       ['got', 173.0, nan],\n",
       "       ['great', 230.0, 654.0],\n",
       "       ['guy', 180.0, nan],\n",
       "       ['half', 162.0, nan],\n",
       "       ['horror', 174.0, 147.0],\n",
       "       ['interesting', 176.0, 147.0],\n",
       "       ['job', nan, 152.0],\n",
       "       ['just', 984.0, 713.0],\n",
       "       ['know', 347.0, 296.0],\n",
       "       ['life', 236.0, 378.0],\n",
       "       ['like', 1085.0, 891.0],\n",
       "       ['little', 259.0, 295.0],\n",
       "       ['long', 183.0, 176.0],\n",
       "       ['look', 200.0, 204.0],\n",
       "       ['looking', 146.0, nan],\n",
       "       ['lot', 178.0, 223.0],\n",
       "       ['love', 215.0, 417.0],\n",
       "       ['make', 459.0, 333.0],\n",
       "       ['makes', 162.0, 251.0],\n",
       "       ['making', 152.0, nan],\n",
       "       ['man', 238.0, 294.0],\n",
       "       ['minutes', 184.0, nan],\n",
       "       ['money', 158.0, nan],\n",
       "       ['movie', 2297.0, 1904.0],\n",
       "       ['movies', 377.0, 338.0],\n",
       "       ['music', nan, 242.0],\n",
       "       ['new', 157.0, 213.0],\n",
       "       ['old', 176.0, 201.0],\n",
       "       ['original', 156.0, nan],\n",
       "       ['people', 450.0, 391.0],\n",
       "       ['performance', nan, 172.0],\n",
       "       ['played', nan, 187.0],\n",
       "       ['plays', nan, 153.0],\n",
       "       ['plot', 368.0, 243.0],\n",
       "       ['point', 145.0, nan],\n",
       "       ['poor', 151.0, nan],\n",
       "       ['pretty', 181.0, 146.0],\n",
       "       ['probably', 151.0, nan],\n",
       "       ['quite', nan, 248.0],\n",
       "       ['real', 197.0, 253.0],\n",
       "       ['really', 620.0, 539.0],\n",
       "       ['reason', 143.0, nan],\n",
       "       ['right', 161.0, 190.0],\n",
       "       ['role', nan, 184.0],\n",
       "       ['saw', 176.0, 177.0],\n",
       "       ['say', 254.0, 212.0],\n",
       "       ['scene', 273.0, 257.0],\n",
       "       ['scenes', 296.0, 291.0],\n",
       "       ['script', 194.0, nan],\n",
       "       ['seen', 306.0, 316.0],\n",
       "       ['series', nan, 197.0],\n",
       "       ['shows', nan, 145.0],\n",
       "       ['story', 485.0, 625.0],\n",
       "       ['terrible', 156.0, nan],\n",
       "       ['thing', 273.0, 155.0],\n",
       "       ['things', 181.0, 171.0],\n",
       "       ['think', 325.0, 379.0],\n",
       "       ['thought', 195.0, 194.0],\n",
       "       ['time', 560.0, 604.0],\n",
       "       ['times', 142.0, 172.0],\n",
       "       ['trying', 158.0, nan],\n",
       "       ['want', 199.0, 158.0],\n",
       "       ['war', nan, 173.0],\n",
       "       ['watch', 369.0, 342.0],\n",
       "       ['watching', 275.0, 185.0],\n",
       "       ['way', 356.0, 390.0],\n",
       "       ['wonderful', nan, 151.0],\n",
       "       ['work', 187.0, 206.0],\n",
       "       ['world', 144.0, 230.0],\n",
       "       ['worst', 219.0, nan],\n",
       "       ['years', 166.0, 253.0],\n",
       "       ['young', nan, 234.0]], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top(all_df.iloc[:, ~all_df.columns.isin(ENGLISH_STOP_WORDS)], n=90).reset_index().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how often the top words from negative appear in the positive reviews and vice versa.  Do these seem like good candidates for determining whether a review is positive or negative? If not, maybe expand to the top 10, or more.  The idea here is to get a list of terms that are pretty distinct between the two sets.\n",
    "\n",
    "Extra: Look into [this resource](https://wordhoard.northwestern.edu/userman/analysis-comparewords.html) for a way to test the count difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(data, word):\n",
    "    counts = data.groupby('positive').sum()\n",
    "    a = counts.loc[True, word]\n",
    "    b = counts.loc[False, word]\n",
    "    c = counts.loc[True].sum()\n",
    "    d = counts.loc[False].sum()\n",
    "    print('counts neg:', b)\n",
    "    print('counts pos:', a)\n",
    "    e1 = c*(a+b)/(c+d)\n",
    "    e2 = d*(a+b)/(c+d)\n",
    "    g = 2*((a*log(a/e1)) + (b*log(b/e2)))\n",
    "    print('G2: ', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "counts neg: 632\n",
      "counts pos: 811\n",
      "G2:  11.479911369377177\n",
      "character\n",
      "counts neg: 364\n",
      "counts pos: 374\n",
      "G2:  0.3417317394041106\n",
      "story\n",
      "counts neg: 485\n",
      "counts pos: 625\n",
      "G2:  9.249181555354653\n",
      "acting\n",
      "counts neg: 369\n",
      "counts pos: 236\n",
      "G2:  39.552133175346455\n"
     ]
    }
   ],
   "source": [
    "# the above gives us some candidates\n",
    "# function to do likelihood ratio test\n",
    "words_to_try = ['good', 'character', 'story', 'acting']\n",
    "for w in words_to_try:\n",
    "    print(w)\n",
    "    log_likelihood(all_df, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary-based sentiment analysis \n",
    "Construct a list of the keywords you've found are good determinants if a review is positive or negative.  Use this list to \"score\" a review based on the number of times that word appears in the review.\n",
    "\n",
    "(Optional) A quick and fancy way of doing this is to use CountVectorizer's vocabulary parameter.  Think how you might be able to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function simple_tokenizer at 0x10a661bf8>,\n",
       "                vocabulary=['good', 'great', 'best', 'love', 'story', 'bad',\n",
       "                            'worst', 'acting', 'poor'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_vocab = ['good', 'great', 'best', 'love', 'story']\n",
    "neg_vocab = ['bad', 'worst', 'acting', 'poor']\n",
    "sentiment_cv = CountVectorizer(tokenizer=simple_tokenizer, vocabulary=pos_vocab+neg_vocab)\n",
    "sentiment_cv.fit(neg+pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you do? How often do the negative reviews have a higher negative score than a positive score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average score\n",
    "neg_sentiment_df = pd.DataFrame(sentiment_cv.transform(neg).toarray(),\n",
    "                      columns=sentiment_cv.get_feature_names())\n",
    "pos_sentiment_df = pd.DataFrame(sentiment_cv.transform(pos).toarray(),\n",
    "                      columns=sentiment_cv.get_feature_names())\n",
    "print('% of negative reviews with higher neg score:', \n",
    "      mean(neg_sentiment_df[neg_vocab].sum(axis=1)>neg_sentiment_df[pos_vocab].sum(axis=1)))\n",
    "print('% of positive reviews with higher pos score:', \n",
    "      mean(pos_sentiment_df[pos_vocab].sum(axis=1)>pos_sentiment_df[neg_vocab].sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based sentiment analysis\n",
    "Above we did some tinkering with our scoring and found it works to some extent, but it's likely not going to work the same on another dataset.  That is, it's not particularly generalizable.  However, modern sentiment analysis has moved away from dictionary-based scoring towards having sentiment be a \"classification\" problem.  \n",
    "\n",
    "For this last section, take a look at the transformers [Pipelines](https://github.com/huggingface/transformers#quick-tour-of-pipelines) functionality.  You'll see that with a few lines of code you can bring in an advanced sentiment analysis model.  Run this against the positive/negative corpus and see how it works compared to your work above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4d3504cefc4b7e835624490e06de93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_parsed = [nlp(d) for d in neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_parsed = [nlp(d) for d in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% neg reviews labelled negative: 0.9180859691808597\n",
      "% pos reviews labelled positive: 0.8593996840442338\n"
     ]
    }
   ],
   "source": [
    "# using % labelled negative vs positive\n",
    "print('% neg reviews labelled negative:', \n",
    "      mean([doc[0]['label']=='NEGATIVE' for doc in neg_parsed]))\n",
    "print('% pos reviews labelled positive:', \n",
    "      mean([doc[0]['label']=='POSITIVE' for doc in pos_parsed]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
