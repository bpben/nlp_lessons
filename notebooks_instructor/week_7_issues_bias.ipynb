{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Issues and bias in NLP\n",
    "This notebook accompanies the week 7 lecture.  This week focuses on examples of how NLP models can be subject to unexpected bias/unwanted learning and potential methods for addressing these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# setup\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from collections import Counter\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "required = {'spacy', 'transformers'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import transformers\n",
    "# this will set the device on which to train\n",
    "device = torch.device(\"cpu\")\n",
    "# if using collab, set your runtime to use GPU and use the line below\n",
    "#device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from group information\n",
    "In this example, we'll show how removing \"group\" information from data can hurt the performance of the model, but that including it might lead to bias in favor of one group versus another.  We'll also show some potential ways to include group information, but account for potential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our reviews dataset\n",
    "# you will need to change this to where ever the file is stored\n",
    "data_location = '../data/assignment_1_reviews.pkl'\n",
    "with open(data_location, 'rb') as f:\n",
    "    all_text = pickle.load(f)\n",
    "neg, pos = all_text.values()\n",
    "# join all reviews\n",
    "all_reviews = np.array(neg+pos)\n",
    "# make into a dataframe, a bit easier to manipulate\n",
    "review_df = pd.DataFrame(all_reviews, columns=['review_text'])\n",
    "review_df['is_positive'] =  [0]*len(neg) + [1]*len(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make up two groups.  Let's say there's a set of \"picky\" reviewers for whom 90% of their reviews are negative and \"nice\" reviewers who are about equally likely to give a positive review as a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_nice\n",
       "0    0.1\n",
       "1    0.5\n",
       "Name: is_positive, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 of each\n",
    "group_size = 1000\n",
    "group_neg_chance = {'picky': 0.9, \n",
    "                    'nice': 0.5}\n",
    "group_data = {}\n",
    "for g in group_neg_chance:\n",
    "    neg_size = int(group_size*group_neg_chance[g])\n",
    "    neg_data = review_df[review_df.is_positive==0].sample(neg_size)\n",
    "    pos_data = review_df[review_df.is_positive==1].sample(group_size-neg_size)\n",
    "    group_data[g] = pd.concat([neg_data, pos_data])\n",
    "    \n",
    "# merge together for model\n",
    "model_data = pd.concat(group_data.values())\n",
    "# add in group indicator\n",
    "model_data['is_nice'] = [0]*group_size + [1]*group_size\n",
    "# quick check\n",
    "model_data.groupby('is_nice')['is_positive'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with group info: 0.912\n",
      "Performance without group info: 0.88\n",
      "Performance for nice group with group info: 0.8765432098765432\n",
      "Performance for picky group with group info: 0.9455252918287937\n",
      "Performance for nice group without group info: 0.831275720164609\n",
      "Performance for picky group without group info: 0.9260700389105059\n"
     ]
    }
   ],
   "source": [
    "# simple: tfidf + svc with and without groups\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data[['review_text', 'is_nice']], \n",
    "                                                    model_data.is_positive,\n",
    "                                                   random_state=42)\n",
    "# fit tfidf\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=0.01)\n",
    "train_vecs = tfidf.fit_transform(X_train['review_text']).toarray()\n",
    "# fit model without group\n",
    "svc_w_group = LinearSVC().fit(\n",
    "    np.concatenate((train_vecs, X_train[['is_nice']]), axis=1),\n",
    "    y_train)\n",
    "# fit model with group\n",
    "svc_no_group = LinearSVC().fit(train_vecs, y_train)\n",
    "# predict on test\n",
    "test_vecs = tfidf.transform(X_test['review_text']).toarray()\n",
    "pred_w_group = svc_w_group.predict(np.concatenate((test_vecs, X_test[['is_nice']]), axis=1))\n",
    "pred_no_group = svc_no_group.predict(test_vecs)\n",
    "\n",
    "print('Performance with group info:', accuracy_score(pred_w_group, y_test))\n",
    "print('Performance without group info:', accuracy_score(pred_no_group, y_test))\n",
    "is_nice = X_test['is_nice'].astype(bool)\n",
    "\n",
    "print('Performance for nice group with group info:', \n",
    "      accuracy_score(pred_w_group[is_nice], \n",
    "                     y_test[is_nice]))\n",
    "print('Performance for picky group with group info:', \n",
    "      accuracy_score(pred_w_group[~is_nice], \n",
    "                     y_test[~is_nice]))\n",
    "print('Performance for nice group without group info:', \n",
    "      accuracy_score(pred_no_group[is_nice], \n",
    "                     y_test[is_nice]))\n",
    "print('Performance for picky group without group info:', \n",
    "      accuracy_score(pred_no_group[~is_nice], \n",
    "                     y_test[~is_nice].astype(bool)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It generally seems that using group info improves our performance across the board.  But is the model unfairly biased against picky reviewers? One way to look at this might be to examine the confusion matrix (i.e. the number of times each class is correctly/incorrectly classified.  Do these numbers vary by group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice group confusion matrix\n",
      " [[107  24]\n",
      " [  6 106]]\n",
      "Picky group confusion matrix\n",
      " [[229  11]\n",
      " [  3  14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Nice group confusion matrix\\n',\n",
    "      confusion_matrix(pred_w_group[is_nice], y_test[is_nice]))\n",
    "print('Picky group confusion matrix\\n',\n",
    "      confusion_matrix(pred_w_group[~is_nice], y_test[~is_nice]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the model wrongly classifies positive reviews as negative 44% (11/25) of the time for picky reviewers, but only 18% (24/130) of the time for nice reviewers.  That's >2x more likely to mis-classify a positive review! Let's see if we can reduce that.\n",
    "\n",
    "### Exercise: Improve group-wise recall\n",
    "Think of some methods we might use to reduce the misclassification of positive reviews for the picky group.  Some strategies you might want to consider is the `class_weight` parameter in SVC or ensembling models (e.g. averaging predicted probabilities, fitting a model to the predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with weights: 0.908\n",
      "Nice group confusion matrix\n",
      " [[105  22]\n",
      " [  8 108]]\n",
      "Picky group confusion matrix\n",
      " [[225   9]\n",
      " [  7  16]]\n"
     ]
    }
   ],
   "source": [
    "# weight classes by inverse frequency in train\n",
    "class_weight = (1/y_train.value_counts(normalize=True)).to_dict()\n",
    "svc_balanced = LinearSVC(class_weight=class_weight).fit(\n",
    "    np.concatenate((train_vecs, X_train[['is_nice']]), axis=1),\n",
    "    y_train)\n",
    "# predict on test\n",
    "test_vecs = tfidf.transform(X_test['review_text']).toarray()\n",
    "pred_balanced = svc_balanced.predict(np.concatenate((test_vecs, X_test[['is_nice']]), axis=1))\n",
    "print('Performance with weights:', accuracy_score(pred_balanced, y_test))\n",
    "print('Nice group confusion matrix\\n',\n",
    "      confusion_matrix(pred_balanced[is_nice], y_test[is_nice]))\n",
    "print('Picky group confusion matrix\\n',\n",
    "      confusion_matrix(pred_balanced[~is_nice], y_test[~is_nice]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We've reduced the missclassification rate for positive reviews for picky reviewers and nice reviewers without hurting accuracy much.  What if we tried just fitting separate models here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of nice model: 0.7942386831275721\n",
      "Performance of picky model: 0.9105058365758755\n",
      "Picky group-picky model confusion matrix\n",
      " [[232  23]\n",
      " [  0   2]]\n"
     ]
    }
   ],
   "source": [
    "# fit model with group\n",
    "is_nice_train = X_train['is_nice'].astype(bool)\n",
    "svc_nice = LinearSVC().fit(train_vecs[is_nice_train], y_train[is_nice_train])\n",
    "svc_picky = LinearSVC().fit(train_vecs[~is_nice_train], y_train[~is_nice_train])\n",
    "# predict \n",
    "test_vecs = tfidf.transform(X_test['review_text']).toarray()\n",
    "pred_nice = svc_nice.predict(test_vecs[is_nice])\n",
    "pred_picky = svc_picky.predict(test_vecs[~is_nice])\n",
    "print('Performance of nice model:', accuracy_score(pred_nice, y_test[is_nice]))\n",
    "print('Performance of picky model:', accuracy_score(pred_picky, y_test[~is_nice]))\n",
    "print('Picky group-picky model confusion matrix\\n',\n",
    "      confusion_matrix(pred_picky, y_test[~is_nice]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the picky model is pretty high, but it seems to achieve that by even more bias against picky users.  What if we combine the information here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of combined predictions: 0.834\n",
      "Picky group confusion matrix\n",
      " [[202   6]\n",
      " [ 30  19]]\n"
     ]
    }
   ],
   "source": [
    "pred_nice = svc_nice.predict(test_vecs)\n",
    "pred_picky = svc_picky.predict(test_vecs)\n",
    "pred_combined = (pred_nice|pred_picky)\n",
    "print('Performance of combined predictions:', accuracy_score(pred_combined, y_test))\n",
    "print('Picky group confusion matrix\\n',\n",
    "      confusion_matrix(pred_combined[~is_nice], y_test[~is_nice]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another reduction in misclassification! Though this seems to cost some amount of accuracy.  We can also use a proxy for confidence using the distance to the separator in the model.  You might also use probability if using a logistic regression.  This is just one way to try that out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of combined predictions: 0.822\n",
      "Picky group confusion matrix\n",
      " [[228  15]\n",
      " [  4  10]]\n"
     ]
    }
   ],
   "source": [
    "pred_nice = svc_nice.decision_function(test_vecs)\n",
    "pred_picky = svc_picky.decision_function(test_vecs)\n",
    "pred_combined = np.mean(np.array([pred_nice, pred_picky]), axis=0)>0\n",
    "print('Performance of combined predictions:', accuracy_score(pred_combined, y_test))\n",
    "print('Picky group confusion matrix\\n',\n",
    "      confusion_matrix(pred_combined[~is_nice], y_test[~is_nice]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really promising here.  A model fit on these two features might be able to learn a smarter combination.\n",
    "\n",
    "## Identifying bias in word vectors\n",
    "In this section, we explore a method for identifying bias in word vectors.  In this case we'll be looking at how to evaluate the \"gender component\" of different vectors and how you might be able to correct for it.  Also, we'll see how that correction may not be totally solving our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gendered word pairs\n",
    "gendered = [('man', 'woman'),\n",
    "           ('he', 'she'),\n",
    "           ('father', 'mother'),\n",
    "           ('son', 'daughter'),\n",
    "           ('men', 'women'),\n",
    "           ('boy', 'girl'),\n",
    "           ('his', 'hers')]\n",
    "\n",
    "# occupation words (ideally \"neutral\")\n",
    "occs = ['nurse', 'homemaker', 'receptionist',\n",
    "       'boss', 'philosopher', 'maestro']\n",
    "\n",
    "# get occ vectors\n",
    "occs_v = np.zeros(shape=(len(occs), 300))\n",
    "for i, occ in enumerate(occs):\n",
    "    occs_v[i] = nlp.vocab[occ].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrating occupation bias\n",
    "# just use he/she\n",
    "he = nlp.vocab['he'].vector\n",
    "she = nlp.vocab['she'].vector\n",
    "occ_he_sim = cosine_similarity(occs_v, he.reshape(1, -1))\n",
    "occ_she_sim = cosine_similarity(occs_v, she.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'similarity to she')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(occ_he_sim, occ_she_sim)\n",
    "for i, occ in enumerate(occs):\n",
    "    ax.annotate(occ, (occ_he_sim[i], occ_she_sim[i]))\n",
    "ax.set_xlabel('similarity to he')\n",
    "ax.set_ylabel('similarity to she')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a simple view of the gender bias embedded in these supposedly neutral occupational terms here.  Another way we might be able to explore this is by creating a \"gender\" vector and measuring the degree to which a word is gendered by its projection on that vector.  \n",
    "\n",
    "In [Bolukbasi et. al (2016)](https://arxiv.org/pdf/1607.06520.pdf) they use the first principle component of a decomposition of the difference between gendered words, but we'll just use the average for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender vector = average of the difference between gendered pairs\n",
    "gender_vec = np.zeros(shape=(300, ))\n",
    "for p in gendered:\n",
    "    gender_vec += nlp.vocab[p[0]].vector - nlp.vocab[p[1]].vector\n",
    "gender_vec = gender_vec/len(gendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nurse -0.6004035111823856\n",
      "homemaker -0.43700202902639257\n",
      "receptionist -0.5232524099656529\n",
      "boss 0.25550318080828693\n",
      "philosopher 0.46069631122875915\n",
      "maestro 0.39486994393427016\n"
     ]
    }
   ],
   "source": [
    "# projection = dot product of vectors, normalized\n",
    "#a = nlp.vocab['test']\n",
    "for i, occ in enumerate(occs):\n",
    "    print(occ, occs_v[i].dot(gender_vec)/gender_vec.dot(gender_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we made the vector he-she, the vector is in the \"direction\" of male-gendered words.  So words that are negative have stronger female associations, positive have stronger male associations.\n",
    "\n",
    "Check out the projection of \"a\", which is close to orthogonal to the gender vector (i.e. has no real gender component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09311277934342956"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['a'].vector.dot(gender_vec)/gender_vec.dot(gender_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore the \"gender\" component of various words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mainpy3] *",
   "language": "python",
   "name": "conda-env-mainpy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
