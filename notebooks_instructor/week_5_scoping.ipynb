{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KD37FKDql7KB"
   },
   "source": [
    "# Week 5: Scoping an NLP project\n",
    "This notebook accompanies the week 5 lecture.  The focus here is to do some surface-level explorations of the wide variety of datasets and models that are publicly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwhFPIGPl7KC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0718 17:09:34.731106 140735234007040 file_utils.py:39] PyTorch version 1.5.1 available.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from collections import Counter\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "required = {'spacy', 'transformers'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.svm import LinearSVC\n",
    "import torch\n",
    "import transformers\n",
    "# this will set the device on which to train\n",
    "device = torch.device(\"cpu\")\n",
    "# if using collab, set your runtime to use GPU and use the line below\n",
    "#device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_J1R3hdWl7KI"
   },
   "source": [
    "### Exploring new dataset and models\n",
    "There are a huge number of NLP datasets available for all kinds of tasks.  Check out some of these sources:\n",
    "\n",
    "- [Google dataset search](https://datasetsearch.research.google.com/)\n",
    "- [Repository of datasets on github](https://github.com/awesomedata/awesome-public-datasets#naturallanguage)\n",
    "- [NLP dataset categorized by task](https://datasets.quantumstat.com/)\n",
    "\n",
    "We'll be exploring some datasets here.  You can either download the full dataset or use the subset I'm providing.  The subset is just a random subsample for efficiency's sake.\n",
    "\n",
    "Datasets:\n",
    "- [Movie spoilers \\(Kaggle\\)](https://www.kaggle.com/rmisra/imdb-spoiler-dataset)\n",
    "\n",
    "- [Wikidata](https://www.wikidata.org/wiki/Wikidata:Database_download)\n",
    "\n",
    "Models/Libraries:\n",
    "- [OpenAI GPT-2 (transformers library)](https://openai.com/blog/better-language-models/)\n",
    "- [BERT (spacy-transformers)]\n",
    "- [Question Answering with (allennlp)]\n",
    "\n",
    "\n",
    "### Movie spoilers dataset\n",
    "In this section we'll be doing some exploration of this dataset, motivated by an analytic question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "aYcOIUdRl7KI",
    "outputId": "5e9f98ea-99af-46a0-d5d0-c86553369d88"
   },
   "outputs": [],
   "source": [
    "# this code is for subsetting, you don't need to run this\n",
    "# read in full data\n",
    "movies = pd.read_json(\n",
    "    open('../data/imdb-spoiler-dataset/IMDB_movie_details.json'),\n",
    "    lines=True)\n",
    "reviews = pd.read_json(\n",
    "    open('../data/imdb-spoiler-dataset/IMDB_reviews.json'),\n",
    "    lines=True)\n",
    "# subset\n",
    "random_state = 42\n",
    "samp_movies = movies.sample(frac=.1, random_state=random_state)\n",
    "samp_reviews = reviews[reviews.movie_id.isin(samp_movies.movie_id)]\n",
    "\n",
    "# output for analysis\n",
    "samp_movies.to_pickle('../data/spoilers_movies.pkl.gz')\n",
    "samp_reviews.to_pickle('../data/spoilers_reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZSW3IHpl7KK"
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "movies = pd.read_pickle('../data/spoilers_movies.pkl.gz')\n",
    "reviews = pd.read_pickle('../data/spoilers_reviews.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "utwV9T3ul7KN",
    "outputId": "51fca7f7-67a0-446d-cd56-d608a4fef1ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 157 entries, 1120 to 915\n",
      "Data columns (total 7 columns):\n",
      "movie_id         157 non-null object\n",
      "plot_summary     157 non-null object\n",
      "duration         157 non-null object\n",
      "genre            157 non-null object\n",
      "rating           157 non-null float64\n",
      "release_date     157 non-null object\n",
      "plot_synopsis    157 non-null object\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 9.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57490 entries, 13974 to 570577\n",
      "Data columns (total 7 columns):\n",
      "review_date       57490 non-null object\n",
      "movie_id          57490 non-null object\n",
      "user_id           57490 non-null object\n",
      "is_spoiler        57490 non-null bool\n",
      "review_text       57490 non-null object\n",
      "rating            57490 non-null int64\n",
      "review_summary    57490 non-null object\n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "count    57490.000000\n",
      "mean      1417.070986\n",
      "std       1096.628524\n",
      "min         41.000000\n",
      "25%        710.000000\n",
      "50%       1022.000000\n",
      "75%       1753.000000\n",
      "max      12645.000000\n",
      "Name: review_text, dtype: float64\n",
      "False    43548\n",
      "True     13942\n",
      "Name: is_spoiler, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# some general EDA\n",
    "print(movies.info())\n",
    "print(reviews.info())\n",
    "# descriptives of review text\n",
    "print(reviews.review_text.apply(len).describe())\n",
    "# what's our class distribution\n",
    "print(reviews.is_spoiler.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WC5O4ebml7KP"
   },
   "source": [
    "## Goal: Can we create method for identifying whether a review is a spoiler?\n",
    "\n",
    "#### Exercise: Scoping the project\n",
    "Let's refer to the [ML project requirements](https://www.jeremyjordan.me/ml-requirements/) article and see if we can evaluate this dataset for its potential to answer that question.\n",
    "\n",
    "Some questions we might want to ask:\n",
    "- Who is the user of this product?\n",
    "- What data might we need?\n",
    "- What data/features do we have to work with?\n",
    "- Is the a simple heuristic here that might be preferable over a model?\n",
    "- How can we iterate here and find improvement?\n",
    "- What is the benefit from getting more elaborate with our design? What is the cost?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Minimal approach\n",
    "Since we already have a dataset tailored to this problem, let's think of some minimal approaches we can apply without even getting into models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tzrM5DGIl7KQ",
    "outputId": "1b46833f-22c8-44a2-ef66-bcb30db846d0"
   },
   "outputs": [],
   "source": [
    "# What about a coin-flip? 50/50 chance a review is a spoiler\n",
    "actual = reviews.is_spoiler\n",
    "pred = np.random.random(size=len(actual))<=0.5\n",
    "accuracy_score(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "gSP2a_CTl7KS",
    "outputId": "0dda152e-f0e2-4bc2-d591-c672185cfd3d"
   },
   "outputs": [],
   "source": [
    "# what if we adjusted our coin flip by genre?\n",
    "# are certain genres more likely to have spoilers?\n",
    "# genre is a list of variable length, so we need to expand that\n",
    "genres = np.unique(np.concatenate(movies.genre.values))\n",
    "genre_dummies = np.zeros(shape=(len(movies), len(genres)))\n",
    "for i, r in enumerate(movies.genre):\n",
    "    for ii, g in enumerate(genres):\n",
    "        if g in r:\n",
    "            genre_dummies[i, ii] = 1\n",
    "df_genre_dummies = pd.DataFrame(genre_dummies,\n",
    "                               columns=genres,\n",
    "                               index=movies.movie_id)\n",
    "reviews_genre = df_genre_dummies.merge(reviews[['movie_id', 'is_spoiler']],\n",
    "                      left_index=True, right_on='movie_id')\n",
    "# now we have the count of spoilers and non spoilers, by genre\n",
    "genre_spoiler = reviews_genre.groupby('is_spoiler').sum().T\n",
    "genre_spoiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CHKqBpiIl7KU",
    "outputId": "eed95a53-1146-4562-a69a-64ffce167fa4"
   },
   "outputs": [],
   "source": [
    "# so what if we just set our prediction to the average spoiler prob of genres?\n",
    "genre_spoiler_prob = genre_spoiler[True]/genre_spoiler.sum(axis=1)\n",
    "# just getting this at the movie level\n",
    "movie_spoiler_prob = movies.genre.apply(lambda x: genre_spoiler_prob.loc[x].mean())\n",
    "movie_spoiler_prob.index = movies.movie_id\n",
    "actual = reviews.is_spoiler\n",
    "pred = np.random.random(size=len(actual))\n",
    "pred = pred <= reviews.movie_id.apply(lambda x: movie_spoiler_prob.loc[x])\n",
    "accuracy_score(actual, pred)\n",
    "# what's the problem with this prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Model-based approach\n",
    "Think of a simple model approach you could use here.  I suggest nothing more complicated than SVC/Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AvViXhaVl7KW",
    "outputId": "4c3c297d-a95a-403d-b1cb-6c3e7ba5df37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40355, 7) (8540, 7) (8595, 7)\n"
     ]
    }
   ],
   "source": [
    "# train/val/test construction\n",
    "# what are the considerations for constructing?\n",
    "np.random.seed(seed=42)\n",
    "# Will use 70/15/15 train/validation/test\n",
    "pct_train = 0.7\n",
    "pct_val = 0.15\n",
    "pct_test = 1-pct_train-pct_val\n",
    "draws = np.random.random(len(reviews))\n",
    "train_bool = draws<=pct_train\n",
    "val_bool = (draws>pct_train)&(draws<=pct_train+pct_val)\n",
    "test_bool = (draws>pct_train+pct_val)&(draws<=pct_train+pct_val+pct_test)\n",
    "train = reviews[train_bool]\n",
    "val = reviews[val_bool]\n",
    "test = reviews[test_bool]\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-K5LkcPql7KZ",
    "outputId": "77297724-1e60-48b9-ead5-4bc7df3f9598"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_genre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0676261cf10d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try the above method, but considering fitting on train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_spoiler_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_genre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_spoiler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_spoiler_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_spoiler_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_spoiler_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmovie_spoiler_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_spoiler_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmovie_spoiler_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews_genre' is not defined"
     ]
    }
   ],
   "source": [
    "# try the above method, but considering fitting on train\n",
    "train_spoiler_prob = reviews_genre[train_bool].groupby('is_spoiler').sum().T\n",
    "train_spoiler_prob = train_spoiler_prob[True]/train_spoiler_prob.sum(axis=1)\n",
    "movie_spoiler_prob = movies.genre.apply(lambda x: train_spoiler_prob.loc[x].mean())\n",
    "movie_spoiler_prob.index = movies.movie_id\n",
    "for d in [train, val]:\n",
    "    actual = d.is_spoiler\n",
    "    pred = np.random.random(size=len(actual))\n",
    "    pred = pred <= d.movie_id.apply(lambda x: movie_spoiler_prob.loc[x])\n",
    "    print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Jyb1pE-rl7Kb",
    "outputId": "7841fcd3-61aa-4e6d-b642-01139a235d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40355, 2030)\n",
      "0.7961343080163549\n",
      "0.7817330210772834\n"
     ]
    }
   ],
   "source": [
    "# now we're getting into models\n",
    "# how does a simple word count+SVM perform?\n",
    "tfidf = TfidfVectorizer(lowercase=False, min_df=0.01)\n",
    "svc = LinearSVC()\n",
    "tfidf_train = tfidf.fit_transform(train.review_text)\n",
    "print(tfidf_train.shape)\n",
    "svc.fit(tfidf_train, train.is_spoiler)\n",
    "for d in [train, val]:\n",
    "    actual = d.is_spoiler\n",
    "    pred = svc.predict(tfidf.transform(d.review_text))\n",
    "    print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6fCFno3Vl7Ke",
    "outputId": "0f39c464-1867-425a-d53e-30d5b09b8dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7629042250030975\n",
      "0.7605386416861827\n"
     ]
    }
   ],
   "source": [
    "# what about topic models?\n",
    "n_components = 10\n",
    "nmf = NMF(n_components=n_components)\n",
    "nmf_train = nmf.fit_transform(tfidf_train)\n",
    "svc.fit(nmf_train, train.is_spoiler)\n",
    "for d in [train, val]:\n",
    "    actual = d.is_spoiler\n",
    "    pred = svc.predict(\n",
    "        nmf.transform(\n",
    "            tfidf.transform(d.review_text)))\n",
    "    print(accuracy_score(actual, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test pipe: [False]\n"
     ]
    }
   ],
   "source": [
    "# output simple review-based models for deployment \n",
    "from sklearn.pipeline import Pipeline\n",
    "tfidf_prod = TfidfVectorizer(lowercase=False, min_df=0.01)\n",
    "tfidf_vecs = tfidf_prod.fit_transform(reviews.review_text)\n",
    "nmf_prod = NMF(n_components=n_components)\n",
    "nmf_vecs = nmf_prod.fit_transform(tfidf_vecs)\n",
    "svc_prod = svc.fit(nmf_vecs, reviews.is_spoiler)\n",
    "pipe = Pipeline(steps=[('tfidf', tfidf_prod), ('nmf', nmf_prod), ('svc', svc_prod)])\n",
    "print('test pipe:', pipe.predict([reviews.review_text.iloc[0]]))\n",
    "pickle.dump(pipe, open('model_pipe.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "34X9A8Sul7Kg",
    "outputId": "6e6dc6e7-55ab-4307-f6af-436431f5e591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       plot_summary  plot_synopsis\n",
      "count    157.000000     157.000000\n",
      "mean     611.044586    8813.070064\n",
      "std      246.397332    8580.499966\n",
      "min       95.000000       0.000000\n",
      "25%      421.000000    3674.000000\n",
      "50%      584.000000    6235.000000\n",
      "75%      730.000000   11521.000000\n",
      "max     1067.000000   51736.000000\n"
     ]
    }
   ],
   "source": [
    "# what is our information inventory?\n",
    "# what text info do we have from movies?\n",
    "print(movies.filter(regex='plot').applymap(lambda x: len(x)).describe())\n",
    "# what if we include movie information?\n",
    "# using summary, which is a bit more concise\n",
    "tfidf_movies = pd.DataFrame(tfidf.transform(movies.plot_summary).toarray(),\n",
    "                            index=movies.movie_id)\n",
    "# shape to fit base dataset\n",
    "movie_features = train.merge(\n",
    "    tfidf_movies, left_on='movie_id', right_index=True)[tfidf_movies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6ij-LtGMl7Ki",
    "outputId": "2da53b1c-4c46-4fd6-874a-3b493a2edae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8264899021186966\n",
      "0.7840749414519906\n"
     ]
    }
   ],
   "source": [
    "# concatenate the two arrays\n",
    "train_feats = np.concatenate([tfidf_train.toarray(),\n",
    "                              movie_features.values], axis=1)\n",
    "svc.fit(train_feats, train.is_spoiler)\n",
    "for d in [train, val]:\n",
    "    actual = d.is_spoiler\n",
    "    movie_feats = d.merge(\n",
    "        tfidf_movies, left_on='movie_id', right_index=True)[tfidf_movies.columns].values\n",
    "    tfidf_feats = tfidf.transform(d.review_text).toarray()\n",
    "    pred = svc.predict(\n",
    "        np.concatenate([tfidf_feats, \n",
    "                        movie_feats], axis=1))\n",
    "    print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3EwEjLOl7Kj"
   },
   "source": [
    "#### Exploring pre-trained models\n",
    "Now that we have a simple, performant baseline, here's where we might want to bring in some pre-trained models.  Or, maybe adapt these pre-trained models via a process called fine-tuning. \n",
    "\n",
    "Let's start by exploring some available models and their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RT4_ynfwl7Kk"
   },
   "outputs": [],
   "source": [
    "# what we're used to: BERT\n",
    "from transformers import BertTokenizer, BertModel \n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "113785db3fff4cebb333547def6a3e7e",
      "a48d098fd5f84b69bd48f781a30cd9cf",
      "250a5b33586e446aa854e931897262b1",
      "32c0e2488c7e4f5da4de89379f2087de",
      "bba9944b17ed42c6bb7c7a41a57d5f32",
      "2665d51083e2495bb59f1cbfceb94cb1",
      "fb98c3946c3a447e8aea928fcd60787f",
      "f48438770cc2493c98dd287c42a3a8d1",
      "964be5aed4bb42fb9f1954cc31c78f44",
      "4ccb577ea8c4496f8f5da7fdb925b598",
      "5aa01c5c96484549aacd377f3a017faa",
      "dda260a25b174799a87bcec9ce7d5fb3",
      "0426dfb932f34544b41a713341f72a66",
      "9358dac6728749958658d9fdad894be5",
      "b20ebae009a043e589d85a01f86769c6",
      "9eb1877f49dc4fa4a1b04c7008db029d",
      "1aa1af45996b48019c8edfc5b6680c93",
      "18a058fbe9de43b8bcbbd8a9c59dfa88",
      "7ce3f1d752e346eeaa1271f5240ea2de",
      "d74668b6b570463baf4864f7c3c623a4",
      "8591a0fd56c847698965b03eb9b27c52",
      "fd9739bca498421cb1ce14f41acc0989",
      "2e022f78c0bb4beaa5f8adcc771b05cd",
      "37e7c6e7381d400cb5a7a1cfb07ee5a3"
     ]
    },
    "colab_type": "code",
    "id": "MRCld7Egl7Km",
    "outputId": "98900edc-a085-4483-9d4f-69201cbfbeed"
   },
   "outputs": [],
   "source": [
    "# what probably makes more sense to use in this setting\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "# Load pre-trained model\n",
    "distil_model = DistilBertModel.from_pretrained(MODEL_NAME)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEsr6N_3l7Kn"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# one dimension of difference: speed\n",
    "samp_reviews = reviews['review_text'].iloc[:5]\n",
    "tokens = tokenizer.batch_encode_plus(samp_reviews,\n",
    "  pad_to_max_length=True, return_tensors=\"pt\", \n",
    "  max_length=512) # BERT expects sequences of 512 tokens\n",
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGS6msmVl7Kq"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "samp_reviews = reviews['review_text'].iloc[:5]\n",
    "tokens = distil_tokenizer.batch_encode_plus(samp_reviews,\n",
    "  pad_to_max_length=True, return_tensors=\"pt\", \n",
    "  max_length=512) # BERT expects sequences of 512 tokens\n",
    "distil_outputs = distil_model(**tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiUBhD7Fl7Ks"
   },
   "source": [
    "We can see here the difference between some of the models out there.  Some will take many hours to run our data through (if we can even do so without crashing the machine!).  BERT is not really designed for CPU work.  It's also not really designed to give document-level representations because it's trained on sentences.\n",
    "\n",
    "Luckily, on Collaboratory, we get access to a GPU, which speeds things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bKXJo9ZRl7Ks",
    "outputId": "f6cf4d12-37dd-40df-9cef-2365ea0bb462"
   },
   "outputs": [],
   "source": [
    "# pass model to GPU\n",
    "distil_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0noZPlLll7Kv"
   },
   "outputs": [],
   "source": [
    "# here we're doing small batches to the model on GPU, we'll load the product of this process later\n",
    "# The model itself takes up a LOT of memory, so we're passing very small batches\n",
    "# note here: You may run out of RAM if you try and run this along with all the above.\n",
    "st = 0\n",
    "batch_size = 5\n",
    "batches = list(range(batch_size, len(reviews), batch_size))+[len(reviews)]\n",
    "doc_rep_collector = []\n",
    "for b in batches:\n",
    "    tokens = distil_tokenizer.batch_encode_plus(\n",
    "        reviews['review_text'][st:b],\n",
    "        pad_to_max_length=True, \n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512)\n",
    "    st = b\n",
    "    tokens.to(device)\n",
    "    outputs = distil_model(**tokens)\n",
    "    # taking the representation of the 'CLS' token (doc-level embedding)\n",
    "    o = outputs[0][:,0].cpu().detach().numpy()\n",
    "    doc_rep_collector.append(o)\n",
    "\n",
    "# stack into array\n",
    "doc_rep_collector = np.concatenate(doc_rep_collector)\n",
    "# to minimize size, can store as 16-bit float\n",
    "doc_rep_collector = doc_rep_collector.astype('float16')\n",
    "# additionally, will store as gzip (pandas can handle this)\n",
    "import gzip\n",
    "pickle.dump(doc_rep_collector, gzip.open('review_bert_vectors.pkl.gz', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GWEwZNjkl7LF",
    "outputId": "38500194-97f5-4ebd-c146-7ad58a05facc"
   },
   "outputs": [],
   "source": [
    "# bringing this portion down here: often running out of RAM on standard runtimes\n",
    "reviews = pd.read_pickle('../data/spoilers_reviews.pkl.gz')\n",
    "np.random.seed(seed=42)\n",
    "# Will use 70/15/15 train/validation/test\n",
    "pct_train = 0.7\n",
    "pct_val = 0.15\n",
    "pct_test = 1-pct_train-pct_val\n",
    "draws = np.random.random(len(reviews))\n",
    "train_bool = draws<=pct_train\n",
    "val_bool = (draws>pct_train)&(draws<=pct_train+pct_val)\n",
    "test_bool = (draws>pct_train+pct_val)&(draws<=pct_train+pct_val+pct_test)\n",
    "train = reviews[train_bool]\n",
    "val = reviews[val_bool]\n",
    "test = reviews[test_bool]\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TUt2g4GVMEM4",
    "outputId": "67002ffd-e503-4634-8d4f-ff788c8cb6c9"
   },
   "outputs": [],
   "source": [
    "# using BERT representations for prediction\n",
    "bert_vectors = pd.read_pickle('../data/review_bert_vectors.pkl.gz')\n",
    "print(bert_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "kF6oAIzvK_PB",
    "outputId": "52b79753-2148-4706-9213-89d6c2ef82fe"
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(bert_vectors[train_bool], train.is_spoiler)\n",
    "for b in [train_bool, val_bool]:\n",
    "    actual = reviews[b].is_spoiler\n",
    "    pred = svc.predict(bert_vectors[b])\n",
    "    print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWSdZH67l7K0"
   },
   "source": [
    "This is bonus, but SpaCy also has an implementation of transformers.  It gives you similar objects to those we're used to working with out of SpaCy.  However, it has some compatibility issues with the `transformers` library (specifically, it requires transformers 2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxsHhmK7l7K0",
    "outputId": "f04521c4-ed44-4a91-ea9a-b5d567b6fb97"
   },
   "outputs": [],
   "source": [
    "# this is what we might refer to as \"tech debt\"\n",
    "# this is tricky to set up on collab, your results may vary...\n",
    "# for spacy-transformers, you'll need a different version of transformers\n",
    "!pip uninstall -y transformers\n",
    "!pip install spacy\n",
    "!pip install spacy-transformers\n",
    "!python -m spacy download en_trf_distilbertbaseuncased_lg\n",
    "# to use with GPU, you'll need to run this on collab\n",
    "!pip uninstall cupy\n",
    "!pip install cupy\n",
    "# restart the kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzBibD-3l7K2"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "gpu = spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_trf_distilbertbaseuncased_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kqsD66nl7K5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "samp_reviews = reviews['review_text'].sample(frac=0.001)\n",
    "parsed = [nlp(doc) for doc in samp_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Bxw_VzGl7K7"
   },
   "source": [
    "In the snippet below, I run the dataset iteratively through DistilBERT, retrieving the representation of the [CLS] token.  This takes a while to run, so we'll just be loading the product of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsVgRe7Tl7K8"
   },
   "outputs": [],
   "source": [
    "st = 0\n",
    "batch_size = 5\n",
    "batches = list(range(batch_size, len(reviews), batch_size))+[len(reviews)]\n",
    "doc_rep_collector = []\n",
    "for b in batches:\n",
    "    cls_rep = [nlp(x)._.trf_last_hidden_state[0] for x in reviews['review_text'][st:b]]\n",
    "    st = b\n",
    "    doc_rep_collector.append(cls_rep)\n",
    "\n",
    "# stack into array\n",
    "doc_rep_collector = np.concatenate(doc_rep_collector)\n",
    "pickle.dump(doc_rep_collector, open('review_bert_vectors.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week_5_scoping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:mainpy3] *",
   "language": "python",
   "name": "conda-env-mainpy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0426dfb932f34544b41a713341f72a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "113785db3fff4cebb333547def6a3e7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_250a5b33586e446aa854e931897262b1",
       "IPY_MODEL_32c0e2488c7e4f5da4de89379f2087de"
      ],
      "layout": "IPY_MODEL_a48d098fd5f84b69bd48f781a30cd9cf"
     }
    },
    "18a058fbe9de43b8bcbbd8a9c59dfa88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1aa1af45996b48019c8edfc5b6680c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ce3f1d752e346eeaa1271f5240ea2de",
       "IPY_MODEL_d74668b6b570463baf4864f7c3c623a4"
      ],
      "layout": "IPY_MODEL_18a058fbe9de43b8bcbbd8a9c59dfa88"
     }
    },
    "250a5b33586e446aa854e931897262b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2665d51083e2495bb59f1cbfceb94cb1",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bba9944b17ed42c6bb7c7a41a57d5f32",
      "value": 442
     }
    },
    "2665d51083e2495bb59f1cbfceb94cb1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e022f78c0bb4beaa5f8adcc771b05cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32c0e2488c7e4f5da4de89379f2087de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f48438770cc2493c98dd287c42a3a8d1",
      "placeholder": "​",
      "style": "IPY_MODEL_fb98c3946c3a447e8aea928fcd60787f",
      "value": " 442/442 [00:12&lt;00:00, 34.8B/s]"
     }
    },
    "37e7c6e7381d400cb5a7a1cfb07ee5a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ccb577ea8c4496f8f5da7fdb925b598": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5aa01c5c96484549aacd377f3a017faa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9358dac6728749958658d9fdad894be5",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0426dfb932f34544b41a713341f72a66",
      "value": 267967963
     }
    },
    "7ce3f1d752e346eeaa1271f5240ea2de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd9739bca498421cb1ce14f41acc0989",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8591a0fd56c847698965b03eb9b27c52",
      "value": 231508
     }
    },
    "8591a0fd56c847698965b03eb9b27c52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9358dac6728749958658d9fdad894be5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "964be5aed4bb42fb9f1954cc31c78f44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5aa01c5c96484549aacd377f3a017faa",
       "IPY_MODEL_dda260a25b174799a87bcec9ce7d5fb3"
      ],
      "layout": "IPY_MODEL_4ccb577ea8c4496f8f5da7fdb925b598"
     }
    },
    "9eb1877f49dc4fa4a1b04c7008db029d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a48d098fd5f84b69bd48f781a30cd9cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b20ebae009a043e589d85a01f86769c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bba9944b17ed42c6bb7c7a41a57d5f32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d74668b6b570463baf4864f7c3c623a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37e7c6e7381d400cb5a7a1cfb07ee5a3",
      "placeholder": "​",
      "style": "IPY_MODEL_2e022f78c0bb4beaa5f8adcc771b05cd",
      "value": " 232k/232k [00:00&lt;00:00, 693kB/s]"
     }
    },
    "dda260a25b174799a87bcec9ce7d5fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eb1877f49dc4fa4a1b04c7008db029d",
      "placeholder": "​",
      "style": "IPY_MODEL_b20ebae009a043e589d85a01f86769c6",
      "value": " 268M/268M [00:09&lt;00:00, 27.4MB/s]"
     }
    },
    "f48438770cc2493c98dd287c42a3a8d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb98c3946c3a447e8aea928fcd60787f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd9739bca498421cb1ce14f41acc0989": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
